# Topic-Modelling-with-Latent-Dirichlet-Allocation

Implemented and developed mathematical models present in David M Blei, Andrew Y Ng, Michael I Jordan paper of Latent Dirichlet Allocation, 2003.

LDA is based on a bayesian probabilistic model where each topic has a discrete probability distribution of words and each document is composed of a mixture of topics. In LDA the topic distribution is assumed to have a Dirichlet prior which gives a smoother topic distribution per document.

In natural language processing, Latent Dirichlet Allocation (LDA) is a widely used topic model proposed by David Blei, Andrew Ng, and Michael Jordan, capable of automatically discovering topics that documents in a corpus contain and explaining similarities between documents. LDA is a three-level hierarchical Bayesian model, and topic modeling is a classic problem in natural language processing.

In this report, we first describe the mechanism of Latent Dirichlet Allocation. We then use two methods to implement LDA: Variational Inference and Collapsed Gibbs Sampling.
